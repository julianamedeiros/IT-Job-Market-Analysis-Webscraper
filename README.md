The goal of this project was to establish the most required skills and technologies for the job of a junior Data Analyst. Since I'm new to the area, I figured the best way of becoming familiar with the professional requirements would be to analyze what the companies were expecting and requiring in their job offers. The idea was to create a program that would access a website of job offers (the chosen one was pracuj.pl) and scrape all the requirements from the most recent offers.

The projectâ€™s directory contains four files (besides the main.py) that represent four steps for the data extraction and processing. For the webcrawler, I used the Selenium library; for HTML scraping, I used Beautifulsoup. Data processing included transforming the data to a pandas dataframe following a star schema with dimentional and fact tables. The created dataframes are loaded in csv files to be later used in Power BI. In the directory, you will also find a Power BI file containing a simple report on the most required technologies for the role of data analyst.
